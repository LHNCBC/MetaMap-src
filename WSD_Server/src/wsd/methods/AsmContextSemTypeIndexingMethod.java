
/****************************************************************************
*
*                          PUBLIC DOMAIN NOTICE                         
*         Lister Hill National Center for Biomedical Communications
*                      National Library of Medicine
*                      National Institues of Health
*           United States Department of Health and Human Services
*                                                                         
*  This software is a United States Government Work under the terms of the
*  United States Copyright Act. It was written as part of the authors'
*  official duties as United States Government employees and contractors
*  and thus cannot be copyrighted. This software is freely available
*  to the public for use. The National Library of Medicine and the
*  United States Government have not placed any restriction on its
*  use or reproduction.
*                                                                        
*  Although all reasonable efforts have been taken to ensure the accuracy 
*  and reliability of the software and data, the National Library of Medicine
*  and the United States Government do not and cannot warrant the performance
*  or results that may be obtained by using this software or data.
*  The National Library of Medicine and the U.S. Government disclaim all
*  warranties, expressed or implied, including warranties of performance,
*  merchantability or fitness for any particular purpose.
*                                                                         
*  For full details, please see the MetaMap Terms & Conditions, available at
*  http://metamap.nlm.nih.gov/MMTnCs.shtml.
*
***************************************************************************/

package wsd.methods;

import java.util.*;
import java.io.*;

import org.apache.log4j.Logger;

import org.jdom.Document;
import org.jdom.Element;
import org.jdom.Namespace;

import wsd.model.*;
import wsd.WSDEnvironment;
import wsd.util.IntArrayIndex;
import wsd.util.IntArrayBinSearchPool;
import gov.nih.nlm.nls.utils.StringUtils;
import java.text.DecimalFormat;

/**
 * Implementation of Semantic Type Indexing in Java.  Based on Susanne
 * Humphrey's semantic-type4 function originally implemented in Lisp.
 * Sussanne's tables have been tranferred to inverted files
 * implemented using binary search table partitioned by term length
 * generated by the module java class wsd.util.IntArrayIndex.
 *
 * <p>Note: this method works by assembling the context from the
 * surrounding utterances of the current utterance in the current
 * citation and is for use by MetaMap version 06 and earlier.
 *
 * <p>This code was developed for National Library of Medicine, Cognitive
 * Science Branch.
 *
 * <p>$Id: AsmSemTypeIndexingMethod.java,v 1.12 2006/09/25 18:38:25 wrogers Exp $</p>
 *
 * <p>Description: Word Sense Disambiguation</p>
 *
 * @version  27jun2006
 * @author   Willie Rogers
 */
public class AsmContextSemTypeIndexingMethod implements DisambiguationMethod
{
  /** which database to use this should be added to server configuration file */
  /** size of semantic type (ST) feature vectors */
  public static final int STVECTORSIZE = 129;
  /** table of semantic type names in order of their occurance within ST feature vectors */
  public static final String stAbbrev[] = {
    "aapp","acab","acty","aggp","alga","amph","anab","anim","anst","antb",
    "arch","bacs","bact","bdsu","bdsy","bhvr","biof","bird","blor","bmod",
    "bodm","bpoc","bsoj","carb","celc","celf","cell","cgab","chem","chvf",
    "chvs","clas","clna","clnd","cnce","comd","diap","dora","dsyn","edac",
    "eehu","eico","elii","emod","emst","enzy","evnt","famg","ffas","fish",
    "fndg","fngs","food","ftcn","genf","geoa","gngm","gora","grpa","grup",
    "hcpp","hcro","hlca","horm","hops","humn","idcn","imft","inbe","inch",
    "inpo","inpr","invt","irda","lang","lbpr","lbtr","lipd","mamm","mbrt",
    "mcha","medd","menp","mnob","mobd","moft","neop","nnon","npop","nsba",
    "nusq","ocac","ocdi","opco","orch","orga","orgf","orgm","orgt","ortf",
    "patf","phob","phpr","phsf","phsu","plnt","podg","popg","prog","qlco",
    "qnco","rcpt","rept","resa","resd","rich","rnlw","sbst","shro","socb",
    "sosy","spco","strd","tisu","tmco","topp","virs","vita","vtbt"
  };
  /** string containing known punctuation */
  public static final String PUNCTUATION = "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~";
  /** string containing known whitespace */
  public static final String WHITESPACE = " \t\n\r\f";
  /** Logger for this class */
  private static Logger logger = Logger.getLogger(AsmContextSemTypeIndexingMethod.class);
  /** set format for scores in test method */
  private static DecimalFormat scoreFormat = new DecimalFormat("0.0000");
  /** Filename for Berkeley DB Term/STI score file used by Semantic Type Indexing Method */
  public static String fSemanticTypeIndexingIndexFilePath =
    WSDEnvironment.properties.getProperty("DISAMB_SERVER_STI_INDEXPATH"); // STI-IF Method
  /** file containing list of allowed words */
  public static String fSemanticTypeIndexingIndexRestrictWordsFile =
    WSDEnvironment.properties.getProperty("DISAMB_SERVER_STI_RESTRICTWORDSFILE", "restrictwords.txt");
  /** file containing list of not allowed words */
  public static String fSemanticTypeIndexingIndexStopWordsFile =
    WSDEnvironment.properties.getProperty("DISAMB_SERVER_STI_STOPWORDSFILE", "stopwords.txt");
  /** list of allowed words */
  public static Set restrictwords;
  /** list of not allowed words */
  public static Set stopwords;
  /** Disk-based pool of partitioned binary search files of ascii-keyed integer arrays */
  public IntArrayBinSearchPool fIndexSemTypeIndexingTable = null;

  static {
    restrictwords = loadWordSet(fSemanticTypeIndexingIndexRestrictWordsFile);
    stopwords = loadWordSet(fSemanticTypeIndexingIndexStopWordsFile);
    logger.info("AsmContextSemTypeIndexingMethod:class init: STI index initialized");
  }

  public AsmContextSemTypeIndexingMethod() 
  {
    try {
      IntArrayIndex iai = IntArrayIndex.getInstance(fSemanticTypeIndexingIndexFilePath);
      fIndexSemTypeIndexingTable = iai.getIntArrayBinSearchPool();
    } catch (IOException e) {
      logger.error(e.getMessage(), e);
    } catch (ClassNotFoundException e) {
      logger.error(e.getMessage(), e);
    } 
  }

  public static Set loadWordSet(String filename)
  {
    Set wordSet = new HashSet();
    try {
      StreamTokenizer st = 
        new StreamTokenizer(new BufferedReader(new FileReader(filename)));
      while(st.nextToken() != StreamTokenizer.TT_EOF) {
        if (st.ttype == StreamTokenizer.TT_WORD)
          wordSet.add(st.sval);
      }
    } catch (FileNotFoundException e) {
      logger.error("loadWordSet:" + e.getMessage(), e);
    } catch (IOException e) {
      logger.error("loadWordSet:" + e.getMessage(), e);
    }
    return wordSet;
  }

  public static boolean isRestrictWord(String term)
  {
    return restrictwords.contains(term.toUpperCase());
  }

  public static boolean notStopWord(String term)
  {
    return (! stopwords.contains(term.toUpperCase()));
  }

  /** Susanne's modification removing QLCO and FNDG from pair of STs for a
      concept.*/
  public static List removeGeneralSemtypesFromPairs(List semanticTypes)
  {
    if (semanticTypes.size() <= 1) 
      return semanticTypes;
    List specificSemanticTypes = new ArrayList();
    for (int i=0; i < semanticTypes.size(); i++)
      {
        String semTypeAbbrev = (String)semanticTypes.get(i);
        if ((semTypeAbbrev != "qlco") && (semTypeAbbrev != "fndg"))
          specificSemanticTypes.add(semTypeAbbrev);
      }
    if (specificSemanticTypes.size() == 0)
      return semanticTypes;
    else
      return specificSemanticTypes;
  }

  /**
   * Close the Semantic Type Indexing Table.
   */
  public void finalize()
  {
    try
      {
        fIndexSemTypeIndexingTable.close();
      }
    catch (IOException e)
      {
        logger.error(e.getMessage(), e);
      }
  }

  /**
   * Get Match
   *
   * @param doc XML DOM representation of document
   * @return list of Result objects
   */
  public List getMatch(Document doc)
  {
    List jdResults = new Vector();
    Element root = doc.getRootElement();
    Namespace ns = root.getNamespace();

    if (logger.isInfoEnabled())
      logger.info("Disambiguating using JDI Method.");
    //get the utterance list
    List utteranceList = root.getChildren("utterance", ns);
    ListIterator utteranceIterator = utteranceList.listIterator();
    while (utteranceIterator.hasNext())
      {
        Element utteranceNode = (Element)utteranceIterator.next();
        Utterance utterance = new Utterance(utteranceNode,ns);

        //get the noun phrase list
        List phraseList = utteranceNode.getChildren("phrase",ns);
        ListIterator phraseIterator = phraseList.listIterator();
        while (phraseIterator.hasNext())
          {
            Element phraseNode = (Element)phraseIterator.next();
            NounPhrase nounPhrase = new NounPhrase(phraseNode,ns);
            if (phraseNode.hasChildren())
              {
                //get the ambiguity list
                Element ambiguitiesNode = phraseNode.getChild("ambiguities",ns);
                List ambiguityList = ambiguitiesNode.getChildren("ambiguity",ns);
                ListIterator ambiguityIterator = ambiguityList.listIterator();
                while (ambiguityIterator.hasNext())
                  {
                    Element ambiguityNode = (Element)ambiguityIterator.next();
                    Ambiguity ambiguity = new Ambiguity(ambiguityNode,ns);
                    //if the ambiguity is marked to be "process"ed, process it
                    //otherwise skip.
                    if (ambiguity.getNeedProcessing())
                      {
                        List candidateList = ambiguityNode.getChildren("candidate",ns);
                        ListIterator candidateIterator = candidateList.listIterator();
                        PreferredNameVector prefNames = new PreferredNameVector();
                        List candidates = new Vector();
                        Candidate candidate = new Candidate();
                        while (candidateIterator.hasNext())
                          {
                            Element candidateNode = (Element)candidateIterator.next();
                            candidate = new Candidate(candidateNode,ns);
                            candidates.add(candidate);
                            String preferredName = candidate.getPreferredConceptName();
                            prefNames.add(preferredName);
                          }
                        List context = getContext(doc,utterance,candidate.getMatchedWords());
                        List bestPrefNames = this.getMatch(utterance,null,context,candidates);
                        //create the Result object that stores the ambiguity result data
                        if (bestPrefNames.size() > 0) {
                          if (bestPrefNames.get(0) instanceof String) {
                            if (bestPrefNames.get(0).equals("NIL")) {
                              jdResults = null;
                            } else if (bestPrefNames.get(0).equals("[Error JDI inputstring is empty or null]")) {
                              jdResults = null;
                            } else if (((String)bestPrefNames.get(0)).startsWith("[Error JDI condition:")) {
                              Result res = new Result();
                              res.setCandidatePreferredConceptNames(prefNames);
                              res.setPreferredConceptNames(bestPrefNames);
                              res.setUi(utterance.getUi());
                              res.setUtterancePos(utterance.getPos());
                              res.setPhrasePos(nounPhrase.getPos());
                              jdResults.add(res);
                            } else if (((String)bestPrefNames.get(0)).equals("[Warning: JDI unable to disambiguate input]")) {
                              jdResults = null;
                            } else {
                              Result res = new Result();
                              res.setCandidatePreferredConceptNames(prefNames);
                              res.setPreferredConceptNames(bestPrefNames);
                              res.setUi(utterance.getUi());
                              res.setUtterancePos(utterance.getPos());
                              res.setPhrasePos(nounPhrase.getPos());
                              jdResults.add(res);
                              if (logger.isDebugEnabled())
                                logger.debug("Result: " + res.getUi() + "|" +
                                             res.getUtterancePos() + "|" +
                                             res.getPhrasePos() + "|" +
                                             res.getCandidatePreferredConceptNames() + "|" +
                                             res.getPreferredConceptNames());
                            }
                          } else {
                            Result res = new Result();
                            res.setCandidatePreferredConceptNames(prefNames);
                            res.setPreferredConceptNames(bestPrefNames);
                            res.setUi(utterance.getUi());
                            res.setUtterancePos(utterance.getPos());
                            res.setPhrasePos(nounPhrase.getPos());
                            jdResults.add(res);
                            if (logger.isDebugEnabled())
                              logger.debug("Result: " + res.getUi() + "|" +
                                           res.getUtterancePos() + "|" +
                                           res.getPhrasePos() + "|" +
                                           res.getCandidatePreferredConceptNames() + "|" +
                                           res.getPreferredConceptNames());
                          }
                        }
                      }
                  }
              }
          }
      }
    if (logger.isInfoEnabled())
      logger.info("Completed disambiguation using JDI Method.");
    return jdResults;
  }

  /** 
   * Assemble context from surrounding utterances within the same citation
   *
   * @param doc            current citation
   * @param currUtterance  current utterance
   * @param wordlist       list of target words of ambiguity
   * @return list containing components of the surrounding context
   */
  private List getContext(Document doc, Utterance currUtterance, String wordlist)
  {
      List context = new Vector();
      List words = new Vector();
      String currSentence = currUtterance.getSentence();
      StringTokenizer tokenizer = new StringTokenizer(wordlist,",");
      while (tokenizer.hasMoreTokens())
        words.add(((String)tokenizer.nextToken()).toLowerCase());
      Element root = doc.getRootElement();
      Namespace ns = root.getNamespace();

      if (logger.isInfoEnabled())
        logger.info("Computing context.");
      //get the utterance list
      List utteranceList = root.getChildren("utterance", ns);
      ListIterator utteranceIterator = utteranceList.listIterator();
      while (utteranceIterator.hasNext())
        {
          Element utteranceNode = (Element)utteranceIterator.next();
 	  Utterance utterance = new Utterance(utteranceNode,ns);
          context.add(utterance.getSentence());
          if (logger.isDebugEnabled())
            logger.debug("added to context: " + utterance.getSentence());
        }
      if (logger.isDebugEnabled())
        logger.debug("The context is:" + context.toString());
      return context;
  }

  // debug
  public void logStiResult(int[] resultVector, int topN)
  {
    SortedMap resultMap = mapStiResult(resultVector);
    int i = 0;
    Iterator mapIterator = resultMap.keySet().iterator();
    while (mapIterator.hasNext() && i < topN) {
      Double score = (Double)mapIterator.next();
      logger.debug( score + " " + resultMap.get(score));
      i++;
    }
  }
  // end debug


  /**
   * Calls the JDI Method and finds the best match in the list of concepts.
   *
   * @see wsd.methods.JdDisambiguator.buildLispSexpMessage
   *
   * @param utterance   The sentence or fragment containing the ambiguity.
   * @param phrases     The phrases in the utterance.
   * @param context     the context of the ambiguity. Initial thought was to have
   *                    several sentences associated with the ambiguity as the context.
   * @param candidates  List of WordSenses of the concepts that cause the ambiguity
   *
   * @return a Result object that represents the best match from JDI method
   * @see wsd.model.WordSense
   */
  public List getMatch(Utterance utterance, List phrases, List context, List candidates)
  {
    StringBuffer sbuf = new StringBuffer();
    sbuf.append(utterance.getSentence().replaceAll("\"","")).append(" ");
    Iterator contextIter = context.iterator();
    while (contextIter.hasNext()) 
      sbuf.append(contextIter.next()).append(" ");
    if (logger.isDebugEnabled())
      logger.debug("calling calculateStiProfileVector(\"" + sbuf + "\")");

    int[] stiResultVector = this.calculateStiProfileVector(sbuf.toString());

    List semTypes = new ArrayList();
    Iterator candidateIterator = candidates.iterator();
    while (candidateIterator.hasNext()) {
      Candidate candidate = (Candidate)candidateIterator.next();
      List candidateSemTypes = removeGeneralSemtypesFromPairs(candidate.getSemTypes());
      for (int i=0; i < candidateSemTypes.size(); i++)
        {
          String semTypeAbbrev = (String)candidateSemTypes.get(i);
          semTypes.add(semTypeAbbrev);
        }
    }
    if (logger.isDebugEnabled())
      logger.debug("candidate semantic types = " + semTypes );
    String resultSemtype = pickBestSemType(stiResultVector, semTypes);
    if (logger.isDebugEnabled())
      logger.debug("semantic types returned from method = " + resultSemtype );
    List resultConcepts = new Vector();
    if (resultSemtype == null) {
      resultConcepts.add("JDI unable to disambiguate input");
    } else {
      boolean done = false;
      for (int j=0; j < candidates.size() && done == false; j++)
        {
          if (((Candidate)candidates.get(j)).getSemTypes().contains(resultSemtype))
            {
              resultConcepts.add(((Candidate)candidates.get(j)).getPreferredConceptName());
              if (logger.isDebugEnabled())
                logger.debug(utterance.getUi() + 
                             ":, " + resultSemtype + 
                             ", added: " + candidates.get(j) + ", " + done);
              done = true;	// only add one candidate that matches semantic type, drop the others.
              break;
            }
        }
    }
    return resultConcepts;
  }

  /**
   * get term vector for term
   * @param term        term to be looked up.
   * @return pointer to termVector if found, null otherwise
   */
  public int[] getTermVector(String term)
  {
    int termVector[] = null;
    try
      {
        if ((termVector = fIndexSemTypeIndexingTable.get(term)) != null )
	  return termVector;
        else
          return null;
      }
    catch (Exception e)
      {
	logger.error(e.getMessage(), e);
	return null;
      }
  }

  /**
   * get term vector for term
   * <p>
   * this version avoids allocation of term vector by requiring caller to supply 
   * pre-allocated term vector of STVECTORSIZE.
   * </p>
   * @param term        term to be looked up.
   * @param termVector  vector to be filled with contents of
   *                    term vector.
   * @return pointer to termVector if found, null otherwise
   */
  public int[] getTermVector(String term, int termVector[])
  {
    try
      {
        if (fIndexSemTypeIndexingTable.get(term, termVector) != null )
	  return termVector;
        else
          return null;
      }
    catch (RuntimeException e)
      {
        logger.error("RuntimeException in getTermVector: term: " + term + ", message: " + e.getMessage(), e);
	return null;
      }
    catch (Exception e)
      {
	logger.error(e.getMessage(), e);
	return null;
      }
  }


  /**
   * Calculate Semantic Type Indexing Vector for supplied tokenized
   * term list.
   *
   * @param token list of tokenized terms to be profiled.
   * @return array of ints representing profile vector
   */
  public int[] calculateStiProfileVector(List tokens)
  {
    int resultVector[] = new int[STVECTORSIZE];
    int sumVector[]    = new int[STVECTORSIZE];
    int termVector[]   = new int[STVECTORSIZE];

    ListIterator st = tokens.listIterator();
    int count = 0;
    while (st.hasNext()) {
      String term = (String)st.next();
      if (isRestrictWord(term) && notStopWord(term)) {
        if (this.getTermVector(term.toUpperCase(), termVector) != null) {
          count++;
          for (int i = 0; i<STVECTORSIZE; i++) {    
            sumVector[i] = sumVector[i] + termVector[i];
          }
        }
      }
    }
    if (count != 0) {
      for (int i = 0; i<STVECTORSIZE; i++) {    
        resultVector[i] = sumVector[i]/count;
      }
    }
    return resultVector;
  }

  /**
   * Calculate Semantic Type Indexing Vector for supplied phrase
   *
   * @param phrase phrase to be profiled.
   * @return array of ints representing profile vector
   */
  public int[] calculateStiProfileVector(String phrase)
  {
    StringBuffer sb = new StringBuffer();
    int resultVector[] = new int[STVECTORSIZE];
    int sumVector[]    = new int[STVECTORSIZE];
    int termVector[]   = new int[STVECTORSIZE];

    StringTokenizer st = new StringTokenizer(phrase, this.PUNCTUATION + this.WHITESPACE);
    int count = 0;
    while (st.hasMoreTokens()) {
      String term = st.nextToken();
      if (isRestrictWord(term) && notStopWord(term)) {
        if (this.getTermVector(term.toUpperCase(), termVector) != null) {
          count++;
          for (int i = 0; i<STVECTORSIZE; i++) {    
            sumVector[i] = sumVector[i] + termVector[i];
          }
	}
      }
    }
    if (count != 0) {
      for (int i = 0; i<STVECTORSIZE; i++) {    
        resultVector[i] = sumVector[i]/count;
      }
    }
    return resultVector;
  }

  /**
   * Generate a sorted map of result by score (key) -> semantic type (value).
   * 
   * @param resultvector 
   * @return sorted map of result vector
   */
  public SortedMap mapStiResult(int[] resultVector)
  {
    // the supplied anonymous comparator sorts the result by score in reverse order.
    SortedMap resultMap = new TreeMap(new Comparator() {
	public int compare(Object o1, Object o2) {
	  int cc = ((Integer)o1).compareTo((Integer)o2);
	  return (cc < 0 ? 1 : cc > 0 ? -1 : 0);
	}
      });
    // load scores into Sorted Map with associated semantic type name.
    for (int i = 0; i<STVECTORSIZE; i++) {
      resultMap.put(new Integer(resultVector[i]), this.stAbbrev[i]);
    }
    return resultMap;
  }

  public void displayStiResult(int[] resultVector, int topN)
  {
    SortedMap resultMap = mapStiResult(resultVector);
    int i = 0;
    Iterator mapIterator = resultMap.keySet().iterator();
    while (mapIterator.hasNext() && i < topN) {
      Integer score = (Integer)mapIterator.next();
      System.out.println( scoreFormat.format(score.doubleValue()*0.0001) + " " + resultMap.get(score) );
      i++;
    }
  }

  public String pickBestSemType(int[] result, List semTypeList) 
  {
    int topScore = 0;
    String topSemType = null;

    for (int i = 0; i<result.length; i++) {
      Iterator stypeIterator = semTypeList.iterator();
      while (stypeIterator.hasNext() ) {
        String semType = (String)stypeIterator.next();
        if (semType.equals(this.stAbbrev[i])) {
          if (result[i] > topScore) {
            topScore = result[i];
            topSemType = semType;
          }
        }
      }
    }
    return topSemType;
  }

  public final static void main(String[] args)
  {
    if (args.length > 0) {
      // read semtypes
      List semtypes = StringUtils.split(args[0], ",");
      // read query
      StringBuffer query = new StringBuffer();
      for (int i = 1; i < args.length; i++) {
        query.append(args[i]).append(" ");
      }
      // WSDEnvironment.initialize();
      // System.out.println("ServerConfigFile: " + WSDEnvironment.SERVER_CONFIG_FILE);
      AsmContextSemTypeIndexingMethod stim = new AsmContextSemTypeIndexingMethod();
      int[] resultVector = stim.calculateStiProfileVector(query.toString());
      stim.displayStiResult(resultVector, 10);
      SortedMap resultMap = stim.mapStiResult(resultVector);
      System.out.println("best semantic type of " + semtypes + " is " + stim.pickBestSemType(resultVector, semtypes));
      WSDEnvironment.shutdown();
    } else {
      System.err.println("usage: java wsd.util.SemanticIndexMethod semtypes query");
      System.err.println("  semtypes are of the form: semtype,semtype,.. (with no spaces)");
      System.exit(1);
    }
  }
}

